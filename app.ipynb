{
 "cells": [
  {
   "cell_type": "raw",
   "id": "07c7a7d6",
   "metadata": {},
   "source": [
    "Read all resumes from ineuron git and try to create a dataframe with `resume name`\n",
    "as index value, and  in column expecting `email id`, `linkedin id`, `git id`\n",
    "and skills as result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dfbcba",
   "metadata": {},
   "source": [
    "### 1- importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5af5bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.utilities.folder_utility import FolderUtility\n",
    "from helpers.handlers.file_factory import FileFactory\n",
    "\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aabd2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCE_FOLDER = 'storage/data_sets/i_resume/same-resume-year-wise-master'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885d7b2e",
   "metadata": {},
   "source": [
    "### 2 - read all files name with in the resource folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb48c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = FolderUtility.get_folder_content_list(RESOURCE_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2953656f",
   "metadata": {},
   "source": [
    "### 3 - confirming files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce229469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12+ (2).docx', '12+.docx', '15+ (1).pdf', '15+.pdf', '20.pdf', '3+ (2).docx', '3+.docx', '3+.pdf', '4 .doc', '4+.docx', '5+ .pdf', '5+.pdf', '5.pdf', '6+.pdf', '7+.pdf', '8+.docx', '8+.pdf', 'freasher .pdf', 'freasher 1.rtf', 'mteh fresher.pdf', '~$3+ (2).docx']\n"
     ]
    }
   ],
   "source": [
    "print(resumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a1553",
   "metadata": {},
   "source": [
    "### 4 - making list of dictionary with email, linkedin , git and skills & index name list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "243fb05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    }
   ],
   "source": [
    "index_name = []\n",
    "grabbed_data_list = []\n",
    "for resume in resumes:\n",
    "    try:\n",
    "        FILE_RELATIVE_PATH = RESOURCE_FOLDER + '/' + resume\n",
    "        FILE_ABS_PATH = os.path.abspath(FILE_RELATIVE_PATH)\n",
    "        file = FileFactory.get_file(FILE_ABS_PATH)\n",
    "        grabbed_data_list.append({\n",
    "            'email': file.get_mail_address(),\n",
    "            'linkedin': file.get_linked_in_address(),\n",
    "            'git': file.get_git_repository_address(),\n",
    "            'skills': file.get_skills()\n",
    "        })\n",
    "        index_name.append(resume)\n",
    "    except Exception as ex:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230dff82",
   "metadata": {},
   "source": [
    "### 5 - confirming index list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b16ecc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12+ (2).docx', '12+.docx', '15+ (1).pdf', '15+.pdf', '20.pdf', '3+ (2).docx', '3+.docx', '3+.pdf', '4 .doc', '4+.docx', '5+ .pdf', '5+.pdf', '5.pdf', '6+.pdf', '7+.pdf', '8+.docx', '8+.pdf', 'freasher .pdf', 'mteh fresher.pdf']\n"
     ]
    }
   ],
   "source": [
    "print(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb204ccb",
   "metadata": {},
   "source": [
    "### 6 - confirming list of dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2260e58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'email': ' ',\n",
       "  'linkedin': ' ',\n",
       "  'git': ' ',\n",
       "  'skills': 'programming_languages =>  Python, Machine Learning (NumPy, Pandas, Matplotlib), Deep Neural Networks (Keras, Tensor Flow), Convolutional Neural Networks, SKlearn Libraries, SPARK Framework, SCALA basics, COBOL, SAS, JCL, VSAM, SQL/PLSQL database =>  DB2, ORACLE coding_skills =>  machine_learning =>  Algorithms,  other_skills =>  programming_skills =>  data_science =>  tools_capability =>  Anaconda, Jupiter Notebook, Pentaho, JIRA, GitHub, IBM Personal Communication tools like - IBM File Manager, CA-7, SDSF, SAR, IBM File manager, QMF, SPUFI, SUPERC, Endevor, Change Man, ITSM Change Management Tool,  operating_system =>  key_skills_and_certifications =>  domains =>  cloud =>  deep_learning =>  project_methodology =>  distribution =>  hardware =>  version_control =>  computer_vision =>  of rates as quick grasp for end business users.  knowledge_in_technology =>  '},\n",
       " {'email': ' sandeep.dasc1@gmail.com ',\n",
       "  'linkedin': ' www.linkedin.com/in/pulavarthy-s-321a92152 ',\n",
       "  'git': ' https://github.com/sandeepdasc1 ',\n",
       "  'skills': 'programming_languages =>  database =>  coding_skills =>  Core PythonNumPyPandasScipyMatplotlibMachine LearningExposure to Random Forest,Decision tree,KNNs, AdaboostXGBoostLinear RegressionLogistic RegressionKMeansother skillsStatisticsHiveSQLUnigraphics NXTeamcenter EngineeringPLM/PDM Tools machine_learning =>   Random Forest,Decision tree,KNNs, AdaboostXGBoostLinear RegressionLogistic RegressionKMeans other_skills =>  StatisticsHiveSQLUnigraphics NXTeamcenter EngineeringPLM/PDM Tools programming_skills =>  data_science =>  tools_capability =>  operating_system =>  key_skills_and_certifications =>  domains =>  cloud =>  deep_learning =>  project_methodology =>  distribution =>  hardware =>  version_control =>  computer_vision =>  knowledge_in_technology =>  '},\n",
       " {'email': ' ',\n",
       "  'linkedin': ' ',\n",
       "  'git': ' ',\n",
       "  'skills': '  Data science Data cleansing Data mining Data modelling Data analysis   Python Algorithms using Machine Learning Tensor flow Pandas  Numpy  SCIKIT learn   Machine learning Linear and Logistic  Regression, Classification- KNN,  Naive Bayes. Clustering  K - means Supervised Learning,  Unsupervised learning  Over fitting,  Parametric and non-Parametric  modelling Deep Learning CNN,RNN  K means, SVM LSTM,Tensor Flow       Operating Systems Windows 98, 2000 server,   XP, Windows 8,10, Android, IOS Office Tools MS office applications   Languages C , Java, VB, PYTHON   Pl/SQL SQL   Verification tools ALM(Quality centre 8.0,8.2) Selenium 2.0 Web drivers (Java) QTP 8.0,8.2, (UFT 12.5)       '},\n",
       " {'email': ' ',\n",
       "  'linkedin': ' ',\n",
       "  'git': ' ',\n",
       "  'skills': '    Machine learning  Client Relationship Management  Process Optimisation/Cost Reduction  Data Science  Statistics  Python  NLP  Deep learning  tensorflow       '},\n",
       " {'email': ' ',\n",
       "  'linkedin': ' ',\n",
       "  'git': ' ',\n",
       "  'skills': '    Python, Machine Learning, Deep Learning, Statistics, Spark, HBase,    Map/Reduce, Big Data, Hadoop ecosystem   PIG, HIVE   Android, Mobile App development   Java, C, MYSQL   AGILE, SCRUM based Development   Design Patterns, Algorithm   Dev-Ops, Dockers, Deployment, CI, GIT   PHP, E-commerce, Healthcare, Enterprise Architecture, MVC        Won Samsung Presidents award, which was given to our team in 2014 among all overseas R&D   Specially sent on Long Term work to Samsung Telecommunication America-Dallas for 1 year (First time in the history of SRIB) Experience Summary SKILL AND KNOWLEDGE AREAS   '},\n",
       " {'email': ' ',\n",
       "  'linkedin': ' ',\n",
       "  'git': ' ',\n",
       "  'skills': 'programming_languages =>  database =>  coding_skills =>  machine_learning =>  and  , Data Aritifical Inteiligence,Statistical modelling ,Natural language Processing,  other_skills =>  programming_skills =>  Python,C,Javascript data_science =>  Machine learning, Data Aritifical Inteiligence,Statistical modelling ,Natural language Processing, Deep learning ,pandas,scikit-learn,keras,matplotlib,Data virtualization Analysi,tensorflow, spark , time series arima model , cnn , RNN , RNN LSTM , tools_capability =>  Pycharm,Pyspyder,Jupyter Notebook operating_system =>  Windows, Linux key_skills_and_certifications =>  domains =>  cloud =>  deep_learning =>  project_methodology =>  distribution =>  hardware =>  version_control =>  computer_vision =>  knowledge_in_technology =>  '},\n",
       " {'email': ' ',\n",
       "  'linkedin': ' ',\n",
       "  'git': ' ',\n",
       "  'skills': 'programming_languages =>  database =>  coding_skills =>  machine_learning =>  other_skills =>  programming_skills =>  data_science =>  tools_capability =>  operating_system =>  key_skills_and_certifications =>  domains =>  cloud =>  deep_learning =>  project_methodology =>  distribution =>  hardware =>  version_control =>  computer_vision =>  knowledge_in_technology =>  '},\n",
       " {'email': ' ', 'linkedin': ' ', 'git': ' ', 'skills': '   '},\n",
       " {'email': ' ',\n",
       "  'linkedin': ' ',\n",
       "  'git': ' ',\n",
       "  'skills': 'programming_languages =>  database =>  coding_skills =>  machine_learning =>  model \\rGood knowledge of Statistics, Linear Algebra, Calculus, Probability Analysis\\rWorking on Internet Of Things devices, Big Data Technologies, machine learning,  AND  other_skills =>  programming_skills =>  data_science =>  tools_capability =>  operating_system =>  key_skills_and_certifications =>  Data Science Master Certification from reputed bootcamp ACADGILD\\rNPTEL  Certification (12 Week) & FDP on Introduction to Internet of Things.\\rNPTEL  Certification (8 Week) & FDP on Big Data computing.\\rAnalytics using Data Preprocessing, Data Wrangling and machine learning model \\rGood knowledge of Statistics, Linear Algebra, Calculus, Probability Analysis\\rWorking on Internet Of Things devices, Big Data Technologies, machine learning, Deep Learning  and artificial intelligence.\\rCoding Skill  domains =>  cloud =>  deep_learning =>  project_methodology =>  distribution =>  hardware =>  version_control =>  computer_vision =>  knowledge_in_technology =>  '},\n",
       " {'email': ' ',\n",
       "  'linkedin': ' ',\n",
       "  'git': ' ',\n",
       "  'skills': 'programming_languages =>  database =>  coding_skills =>  machine_learning =>  ,  Machine Learning,Data Analysis, Artificial intelligence, Natural Language Processing,pandas,scikit learn,matplotlib,python,Data Cleaning other_skills =>  programming_skills =>  Python,Java data_science =>  tools_capability =>  pycharm,Pyspyder,Jupyter  Notebook, Eclipse operating_system =>  Windows, Cent OS , Red Hat, Ubuntu key_skills_and_certifications =>  domains =>  Investment Banking cloud =>  GAIA ( Pivotal Cloud Foundry ) deep_learning =>  Tensorflow, keras,CNN,faster CNN, RNN, RNN – LSTM, Vgg16,Resnet-50, Mobilenet, SSD,Harcascade,Tensorflow JS  project_methodology =>  Agile SCRUM distribution =>  Cloudera hardware =>  Nvidiatesla,Raspberry pi 3b+  version_control =>  GIT, BIT BUCKET computer_vision =>  , Machine learning and NLP solution on web based application ,Azure platform using kubernetes services and Raspberry pi .  , natural language processing , hands-on experience leveraging machine learning, deep \\t learning ,transfer learning  models to solve challenging business problems. Tensorflow, keras,CNN,faster CNN, RNN, RNN – LSTM, Vgg16,Resnet-50, Mobilenet, SSD,Harcascade,Tensorflow JS  , Deep leaning algorithms, Raspberry pi , GAIA, Nvidia tesla k80 .  system for Real time surveillance, smart parking check post , Virtual banking .  , NLP and Python . use cases so far I have involved  multiple use cases in like Traders Monitoring system , surveillance system for employees (Smart Parking Check Post) and may projects are in pipeline  .  knowledge_in_technology =>  '},\n",
       " {'email': ' ', 'linkedin': ' ', 'git': ' ', 'skills': '   '},\n",
       " {'email': ' ', 'linkedin': ' ', 'git': ' ', 'skills': '   '},\n",
       " {'email': ' ', 'linkedin': ' ', 'git': ' ', 'skills': '   '},\n",
       " {'email': ' ', 'linkedin': ' ', 'git': ' ', 'skills': '   '},\n",
       " {'email': ' ', 'linkedin': ' ', 'git': ' ', 'skills': '   '},\n",
       " {'email': ' ',\n",
       "  'linkedin': ' ',\n",
       "  'git': ' ',\n",
       "  'skills': 'programming_languages =>  database =>  coding_skills =>  machine_learning =>  Machine Learning,Data Analysis, Artificial intelligence, Natural Language Processing, Pandas, Scikit learn, Matplotlib, Python, Data Cleaning ,  other_skills =>  programming_skills =>  Python, data_science =>  tools_capability =>  Pycharm, Pyspyder, Jupyter  Notebook, EclipseCloudGoogle  operating_system =>  Windows, Ubuntu key_skills_and_certifications =>  domains =>  Marketing Analytics cloud =>  Google Cloud,Azure,AWS,GAIA ( Pivotal Cloud Foundry ) deep_learning =>  Tensorflow, keras, CNN, Faster CNN, RNN, RNN – LSTM, Vgg16, Resnet-50, Mobilenet, SSD, Harcascade, Tensorflow JS  project_methodology =>  Agile SCRUM distribution =>  Cloudera  hardware =>  Nvidia Tesla,Raspberry Pi 3b+  version_control =>  computer_vision =>  Intermediate , NLP and Python. , Machine learning and NLP solution on web based application, Azure platform using kubernetes services and Raspberry pi.  Tensorflow, keras, CNN, Faster CNN, RNN, RNN – LSTM, Vgg16, Resnet-50, Mobilenet, SSD, Harcascade, Tensorflow JS  knowledge_in_technology =>  '},\n",
       " {'email': ' ', 'linkedin': ' ', 'git': ' ', 'skills': '   '},\n",
       " {'email': ' ', 'linkedin': ' ', 'git': ' ', 'skills': '   '},\n",
       " {'email': ' ', 'linkedin': ' ', 'git': ' ', 'skills': '   '}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grabbed_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49103418",
   "metadata": {},
   "source": [
    "### 7 - making dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b85775",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = pd.DataFrame(grabbed_data_list,index=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bec5bc",
   "metadata": {},
   "source": [
    "### 8 - showing resumes dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b920680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>linkedin</th>\n",
       "      <th>git</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12+ (2).docx</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>programming_languages =&gt;  Python, Machine Lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12+.docx</th>\n",
       "      <td>sandeep.dasc1@gmail.com</td>\n",
       "      <td>www.linkedin.com/in/pulavarthy-s-321a92152</td>\n",
       "      <td>https://github.com/sandeepdasc1</td>\n",
       "      <td>programming_languages =&gt;  database =&gt;  coding_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15+ (1).pdf</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Data science Data cleansing Data mining Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15+.pdf</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Machine learning  Client Relationship Mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.pdf</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Python, Machine Learning, Deep Learning, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3+ (2).docx</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>programming_languages =&gt;  database =&gt;  coding_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3+.docx</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>programming_languages =&gt;  database =&gt;  coding_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3+.pdf</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 .doc</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>programming_languages =&gt;  database =&gt;  coding_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4+.docx</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>programming_languages =&gt;  database =&gt;  coding_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5+ .pdf</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5+.pdf</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.pdf</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6+.pdf</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7+.pdf</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8+.docx</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>programming_languages =&gt;  database =&gt;  coding_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8+.pdf</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freasher .pdf</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mteh fresher.pdf</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      email  \\\n",
       "12+ (2).docx                                  \n",
       "12+.docx           sandeep.dasc1@gmail.com    \n",
       "15+ (1).pdf                                   \n",
       "15+.pdf                                       \n",
       "20.pdf                                        \n",
       "3+ (2).docx                                   \n",
       "3+.docx                                       \n",
       "3+.pdf                                        \n",
       "4 .doc                                        \n",
       "4+.docx                                       \n",
       "5+ .pdf                                       \n",
       "5+.pdf                                        \n",
       "5.pdf                                         \n",
       "6+.pdf                                        \n",
       "7+.pdf                                        \n",
       "8+.docx                                       \n",
       "8+.pdf                                        \n",
       "freasher .pdf                                 \n",
       "mteh fresher.pdf                              \n",
       "\n",
       "                                                      linkedin  \\\n",
       "12+ (2).docx                                                     \n",
       "12+.docx           www.linkedin.com/in/pulavarthy-s-321a92152    \n",
       "15+ (1).pdf                                                      \n",
       "15+.pdf                                                          \n",
       "20.pdf                                                           \n",
       "3+ (2).docx                                                      \n",
       "3+.docx                                                          \n",
       "3+.pdf                                                           \n",
       "4 .doc                                                           \n",
       "4+.docx                                                          \n",
       "5+ .pdf                                                          \n",
       "5+.pdf                                                           \n",
       "5.pdf                                                            \n",
       "6+.pdf                                                           \n",
       "7+.pdf                                                           \n",
       "8+.docx                                                          \n",
       "8+.pdf                                                           \n",
       "freasher .pdf                                                    \n",
       "mteh fresher.pdf                                                 \n",
       "\n",
       "                                                git  \\\n",
       "12+ (2).docx                                          \n",
       "12+.docx           https://github.com/sandeepdasc1    \n",
       "15+ (1).pdf                                           \n",
       "15+.pdf                                               \n",
       "20.pdf                                                \n",
       "3+ (2).docx                                           \n",
       "3+.docx                                               \n",
       "3+.pdf                                                \n",
       "4 .doc                                                \n",
       "4+.docx                                               \n",
       "5+ .pdf                                               \n",
       "5+.pdf                                                \n",
       "5.pdf                                                 \n",
       "6+.pdf                                                \n",
       "7+.pdf                                                \n",
       "8+.docx                                               \n",
       "8+.pdf                                                \n",
       "freasher .pdf                                         \n",
       "mteh fresher.pdf                                      \n",
       "\n",
       "                                                             skills  \n",
       "12+ (2).docx      programming_languages =>  Python, Machine Lear...  \n",
       "12+.docx          programming_languages =>  database =>  coding_...  \n",
       "15+ (1).pdf         Data science Data cleansing Data mining Data...  \n",
       "15+.pdf               Machine learning  Client Relationship Mana...  \n",
       "20.pdf                Python, Machine Learning, Deep Learning, S...  \n",
       "3+ (2).docx       programming_languages =>  database =>  coding_...  \n",
       "3+.docx           programming_languages =>  database =>  coding_...  \n",
       "3+.pdf                                                               \n",
       "4 .doc            programming_languages =>  database =>  coding_...  \n",
       "4+.docx           programming_languages =>  database =>  coding_...  \n",
       "5+ .pdf                                                              \n",
       "5+.pdf                                                               \n",
       "5.pdf                                                                \n",
       "6+.pdf                                                               \n",
       "7+.pdf                                                               \n",
       "8+.docx           programming_languages =>  database =>  coding_...  \n",
       "8+.pdf                                                               \n",
       "freasher .pdf                                                        \n",
       "mteh fresher.pdf                                                     "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc40a28d",
   "metadata": {},
   "source": [
    "### 9 - Confirming full view of a skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a2596e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'programming_languages =>  Python, Machine Learning (NumPy, Pandas, Matplotlib), Deep Neural Networks (Keras, Tensor Flow), Convolutional Neural Networks, SKlearn Libraries, SPARK Framework, SCALA basics, COBOL, SAS, JCL, VSAM, SQL/PLSQL database =>  DB2, ORACLE coding_skills =>  machine_learning =>  Algorithms,  other_skills =>  programming_skills =>  data_science =>  tools_capability =>  Anaconda, Jupiter Notebook, Pentaho, JIRA, GitHub, IBM Personal Communication tools like - IBM File Manager, CA-7, SDSF, SAR, IBM File manager, QMF, SPUFI, SUPERC, Endevor, Change Man, ITSM Change Management Tool,  operating_system =>  key_skills_and_certifications =>  domains =>  cloud =>  deep_learning =>  project_methodology =>  distribution =>  hardware =>  version_control =>  computer_vision =>  of rates as quick grasp for end business users.  knowledge_in_technology =>  '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes.loc['12+ (2).docx','skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6d7374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
